{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.metrics import make_scorer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, LeaveOneOut\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from scipy.stats.mstats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "\n",
    "xin= np.load(\"./X_train.npy\")\n",
    "yin= np.load(\"./y_train.npy\")\n",
    "xout= np.load(\"./X_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dims=[50, 70, 75, 80, 90, 100, 120, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_components= 40\n",
    "\n",
    "pca = PCA(n_components=n_components, svd_solver='auto',\n",
    "              whiten=True).fit(xin)\n",
    "\n",
    "X_pca = pca.transform(xin)\n",
    "\n",
    "#print(pca.explained_variance_.shape)\n",
    "#print(pca.explained_variance_ratio_.shape)\n",
    "y=pca.explained_variance_\n",
    "#take the highest expl. variance\n",
    "#print(pca.explained_variance_)\n",
    "\n",
    "#print(pca.explained_variance_)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "#print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "x = np.arange(0, n_components) \n",
    "plt.xticks(x)\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dimReduction(n_components, X_train):\n",
    "\n",
    "    h= 50\n",
    "    w= 37\n",
    "    t0 = time()\n",
    "    print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "          % (n_components, X_train.shape[0]))\n",
    "    pca = PCA(n_components=n_components, svd_solver='auto',\n",
    "              whiten=True).fit(X_train)\n",
    "\n",
    "    eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "    print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "    X_pca = pca.transform(X_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.37088608  1.03670886  1.28481013  0.5         1.28227848  1.34810127\n",
      "  1.23164557]\n",
      "[ 0.17020273  0.12871287  0.15951595  0.06207764  0.15920163  0.16737388\n",
      "  0.15291529]\n"
     ]
    }
   ],
   "source": [
    "#unbalanced dataset!\n",
    "freq= itemfreq(yin)\n",
    "\n",
    "#print (freq)\n",
    "#print(freq[:,1])\n",
    "#print(np.sum(freq[:,1]))\n",
    "tot= np.sum(freq[:,1])\n",
    "sample_weight=(1-(np.sinh(freq[:,1]/(tot)))) \n",
    "sample_weight = sample_weight / float(max(sample_weight))\n",
    "#print(sample_weight)\n",
    "\n",
    "w2= 1.5 - freq[:,1]/max(freq[:,1])\n",
    "print (w2)\n",
    "w3= w2/np.sum(w2)\n",
    "print(w3)\n",
    "\n",
    "dic1= {0: sample_weight[0],\n",
    "      1: sample_weight[1],\n",
    "      2: sample_weight[2],\n",
    "      3: sample_weight[3],\n",
    "      4: sample_weight[4],\n",
    "      5: sample_weight[5],\n",
    "      6: sample_weight[6],\n",
    "     }\n",
    "\n",
    "dic2= {0: w2[0],\n",
    "      1: w2[1],\n",
    "      2: w2[2],\n",
    "      3: w2[3],\n",
    "      4: w2[4],\n",
    "      5: w2[5],\n",
    "      6: w2[6],\n",
    "     }\n",
    "\n",
    "dic3= {0: w3[0],\n",
    "      1: w3[1],\n",
    "      2: w3[2],\n",
    "      3: w3[3],\n",
    "      4: w3[4],\n",
    "      5: w3[5],\n",
    "      6: w3[6],\n",
    "     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export(filename, x):\n",
    "    fo = open( filename , 'w' )\n",
    "    fo.write(x)\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniformDataset(x, y):\n",
    "    freq= itemfreq(y)\n",
    "    minOcc= min(freq[:,1])\n",
    "    #print(minOcc)\n",
    "    xred= np.empty((0,1850))\n",
    "    yred= np.array([])\n",
    "    for i in range(y.shape[0]):\n",
    "        freqnew= itemfreq(yred)\n",
    "        if(freqnew.shape== (7,2)):\n",
    "            occ= freqnew[y[i],1]\n",
    "        else:\n",
    "            occ= 0\n",
    "        if(occ <= minOcc):\n",
    "            xred= np.vstack((xred, [x[i, :]]))\n",
    "            yred= np.append(yred, y[i])\n",
    "    return (xred,yred)\n",
    "    #print(xred.shape)\n",
    "    #print(yred.shape)\n",
    "    #print(itemfreq(yred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def underSampling(x, y):\n",
    "    cc = ClusterCentroids()\n",
    "    x_resampled, y_resampled = cc.fit_sample(x, y)\n",
    "    return (x_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overSampling(x, y):\n",
    "    sm = SMOTE(kind='svm')\n",
    "    x_resampled, y_resampled = sm.fit_sample(x, y)\n",
    "    return (x_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weightedF1(y, predictions):\n",
    "    f1= f1_score(y, predictions, average=None)\n",
    "    occ= itemfreq(y)\n",
    "    count= np.sum(occ[:,1])\n",
    "    score= 0.0\n",
    "    v=np.empty(occ[:,1].shape[0])\n",
    "    for i in range(len(f1)):\n",
    "        v[i]= (1-occ[i,1]/count)*f1[i]\n",
    "        score = score+ (1-occ[i,1]/count)*f1[i]\n",
    "    return score\n",
    "#y=[1, 2, 3, 3, 3]\n",
    "#pred=[1, 2, 2, 3, 1]\n",
    "#r=weightedF1(y, pred)\n",
    "#print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildModel(param_grid, dim, x, y):\n",
    "    t0 = time()\n",
    "    x_n= dimReduction(dim, x)\n",
    "    print(\"Fitting the classifier to the training set\")\n",
    "    #f1custom= make_scorer(weightedF1, greater_is_better=True)\n",
    "    model = GridSearchCV(SVC(decision_function_shape='ovr'),\n",
    "            param_grid, cv=StratifiedKFold(n_splits=10),\n",
    "            n_jobs=-1)\n",
    "    model = model.fit(x_n, y)\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"DIMENSIONS:\")\n",
    "    print(dim)\n",
    "    #print(\"ker:\")\n",
    "    #print(ker)\n",
    "    #print(\"Best estimator found by grid search:\")\n",
    "    #print(model.best_estimator_)\n",
    "    print(\"Best score found by grid search:\")\n",
    "    print(model.best_score_)\n",
    "    print(\"Best params found by grid search:\")\n",
    "    print(model.best_params_)\n",
    "    print(\"\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, x, y):\n",
    "    t0 = time()\n",
    "    print(\"Predicting people's names on the test set\")\n",
    "    y_pred = model.predict(x)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    score= f1_score(y, y_pred, average='weighted')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 80 eigenfaces from 357 faces\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.094s\n",
      "Fitting the classifier to the training set\n",
      "done in 48.042s\n",
      "DIMENSIONS:\n",
      "80\n",
      "Best score found by grid search:\n",
      "0.78431372549\n",
      "Best params found by grid search:\n",
      "{'C': 2.0, 'kernel': 'rbf', 'gamma': 0.0078125, 'class_weight': 'balanced'}\n",
      "\n",
      "\n",
      "Extracting the top 100 eigenfaces from 357 faces\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.085s\n",
      "Fitting the classifier to the training set\n",
      "done in 59.973s\n",
      "DIMENSIONS:\n",
      "100\n",
      "Best score found by grid search:\n",
      "0.775910364146\n",
      "Best params found by grid search:\n",
      "{'C': 2.0, 'gamma': 0.00390625, 'kernel': 'rbf', 'class_weight': 'balanced'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best: \n",
      "0.78431372549\n",
      "params:\n",
      "{'C': 2.0, 'kernel': 'rbf', 'gamma': 0.0078125, 'class_weight': 'balanced'}\n",
      "dim\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "a=2\n",
    "expC= np.arange(-5.,17.)\n",
    "c=np.power(a, expC)\n",
    "\n",
    "expG= np.arange(-15.,4.)\n",
    "\n",
    "gam=np.power(a, expG)\n",
    "\n",
    "\n",
    "param_grid = {'C': c,\n",
    "              'gamma': gam,\n",
    "              'kernel':['rbf'],\n",
    "              'class_weight': ['balanced']\n",
    "             }\n",
    "\n",
    "dims=[80, 100]\n",
    "\n",
    "#(xnew,ynew)=uniformDataset(xin,yin)\n",
    "\n",
    "result=0.0\n",
    "\n",
    "x_ov, y_ov= underSampling(xin, yin)\n",
    "\n",
    "for i in range(len(dims)):\n",
    "    model= buildModel(param_grid, dims[i], x_ov, y_ov)\n",
    "    tmp= model.best_score_\n",
    "    if(tmp > result):\n",
    "        result=  tmp\n",
    "        params= model.best_params_\n",
    "        d= dims[i]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Best: \")\n",
    "print(result)\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print(\"dim\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d4dcc54292f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mexpC\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "a=2\n",
    "expC= np.arange(-5.,17.)\n",
    "c= [2]\n",
    "\n",
    "#expG= np.arange(-15.,4.)\n",
    "#gam=np.power(a, expG)\n",
    "\n",
    "gam= [0.0078125,0.008 ,0.006, 0.005, 0.002, 0.001 , 0.009, 0.008,\n",
    "      0.0095, 0.0099, 0.01, 0.03, 0.04, 0.05, 0.0085, 0.0001 \n",
    "      , 0.0009, 0.0005, 0.0007, 0.0001, 0.02, 0.1, 0.5, 0.75,\n",
    "     0.9, 1, 0.00001, 0.00003, 0.0008]\n",
    "\n",
    "param_grid = {'C': c,\n",
    "              'gamma': gam,\n",
    "              'kernel':['rbf'],\n",
    "              'class_weight': [dic2]\n",
    "             }\n",
    "\n",
    "dims=[80]\n",
    "\n",
    "#(xnew,ynew)=uniformDataset(xin,yin)\n",
    "\n",
    "result=0.0\n",
    "\n",
    "for i in range(len(dims)):\n",
    "    model= buildModel(param_grid, dims[i], xin, yin)\n",
    "    tmp= model.best_score_\n",
    "    if(tmp > result):\n",
    "        result=  tmp\n",
    "        params= model.best_params_\n",
    "        d= dims[i]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Best: \")\n",
    "print(result)\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print(\"dim\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 80 eigenfaces from 966 faces\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.253s\n",
      "Fitting the classifier to the training set\n",
      "done in 13.933s\n",
      "DIMENSIONS:\n",
      "80\n",
      "Best score found by grid search:\n",
      "0.801436801442\n",
      "Best params found by grid search:\n",
      "{'C': 0.03125, 'kernel': 'linear', 'class_weight': {0: 1.3708860759493671, 1: 1.0367088607594936, 2: 1.2848101265822784, 3: 0.5, 4: 1.2822784810126582, 5: 1.3481012658227849, 6: 1.2316455696202531}}\n",
      "\n",
      "\n",
      "Extracting the top 150 eigenfaces from 966 faces\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.347s\n",
      "Fitting the classifier to the training set\n",
      "done in 20.659s\n",
      "DIMENSIONS:\n",
      "150\n",
      "Best score found by grid search:\n",
      "0.79753815337\n",
      "Best params found by grid search:\n",
      "{'C': 0.03125, 'kernel': 'linear', 'class_weight': {0: 1.3708860759493671, 1: 1.0367088607594936, 2: 1.2848101265822784, 3: 0.5, 4: 1.2822784810126582, 5: 1.3481012658227849, 6: 1.2316455696202531}}\n",
      "\n",
      "\n",
      "Extracting the top 100 eigenfaces from 966 faces\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.203s\n",
      "Fitting the classifier to the training set\n",
      "done in 13.919s\n",
      "DIMENSIONS:\n",
      "100\n",
      "Best score found by grid search:\n",
      "0.805091695476\n",
      "Best params found by grid search:\n",
      "{'class_weight': {0: 1.3708860759493671, 1: 1.0367088607594936, 2: 1.2848101265822784, 3: 0.5, 4: 1.2822784810126582, 5: 1.3481012658227849, 6: 1.2316455696202531}, 'kernel': 'linear', 'C': 0.03125}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best: \n",
      "0.805091695476\n",
      "params:\n",
      "{'class_weight': {0: 1.3708860759493671, 1: 1.0367088607594936, 2: 1.2848101265822784, 3: 0.5, 4: 1.2822784810126582, 5: 1.3481012658227849, 6: 1.2316455696202531}, 'kernel': 'linear', 'C': 0.03125}\n",
      "dim\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#LINEAR\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "a=2\n",
    "expC= np.arange(-5.,17.)\n",
    "c=np.power(a, expC)\n",
    "\n",
    "param_grid = {'C': c,\n",
    "              'kernel':['linear'],\n",
    "              'class_weight': [dic2]\n",
    "             }\n",
    "\n",
    "dims=[80, 150, 100]\n",
    "\n",
    "#(xnew,ynew)=uniformDataset(xin,yin)\n",
    "\n",
    "result=0.0\n",
    "\n",
    "for i in range(len(dims)):\n",
    "    model= buildModel(param_grid, dims[i], xin, yin)\n",
    "    tmp= model.best_score_\n",
    "    if(tmp > result):\n",
    "        result=  tmp\n",
    "        params= model.best_params_\n",
    "        d= dims[i]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Best: \")\n",
    "print(result)\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print(\"dim\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CHI square test\n",
    "def chisq(xin, yin, k):\n",
    "    \n",
    "    x_new = SelectKBest(f_classif, k=k).fit_transform(xin,yin)\n",
    "    \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modChi(ker, param_grid, k, x, y):\n",
    "    t0 = time()\n",
    "    xin= chisq(x,y,k)\n",
    "    print(\"Fitting the classifier to the training set\")\n",
    "    model = GridSearchCV(SVC(kernel=ker, class_weight='balanced', decision_function_shape='ovr'), param_grid, cv=5, scoring='f1_micro')\n",
    "    model = model.fit(xin, y)\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"DIMENSIONS:\")\n",
    "    print(k)\n",
    "    print(\"ker:\")\n",
    "    print(ker)\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(model.best_estimator_)\n",
    "    print(\"Best score found by grid search:\")\n",
    "    print(model.best_score_)\n",
    "    print(\"Best params found by grid search:\")\n",
    "    print(model.best_params_)\n",
    "    print(\"\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [1],\n",
    "              'gamma': [0.008, 0.009, 0.0085, 0.01], }\n",
    "\n",
    "k= [100]\n",
    "\n",
    "result=0.0\n",
    "\n",
    "for i in range(len(k)):\n",
    "    model= modChi('rbf',param_grid, k[i], xin, yin)\n",
    "    tmp= model.best_score_\n",
    "    if(tmp > result):\n",
    "        result=  tmp\n",
    "        params= model.best_params_\n",
    "        dim= k[i]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Best: \")\n",
    "print(result)\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print(\"dim\")\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [100, 50, 20, 10, 1, 0.1, 0.001, 0.0001],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.005, 0.0001, 0.0005, 0.000001], \n",
    "              'coef0': [0, 0.01, 0.001, 0.0001, 100, 1000]}\n",
    "\n",
    "result= 0.0\n",
    "\n",
    "for i in range(len(dims)):\n",
    "    model= buildModel('sigmoid',param_grid, dims[i], xin, yin)\n",
    "    tmp= model.best_score_\n",
    "    if(tmp > result):\n",
    "        result=  tmp\n",
    "        params= model.best_params_\n",
    "        d= dims[i]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Best: \")\n",
    "print(result)\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print(\"dim\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "param_range = np.logspace(-5, -1, 5)\n",
    "x_in= dimReduction(90,xin)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    SVC(C=1), x_in, yin, param_name=\"gamma\", param_range=param_range,\n",
    "    cv=2, scoring=\"f1_micro\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d4e80bc83eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mparam_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_in\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdimReduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "###### from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "param_range = np.logspace(-2.3, -1, 5)\n",
    "print(param_range)\n",
    "x_in= dimReduction(75,xin)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    SVC(C=1), x_in, yin, param_name=\"gamma\", param_range=param_range,\n",
    "    cv=StratifiedKFold(n_splits=3), scoring=\"f1_micro\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scale(x):\n",
    "    xi=zscore(x, axis=1)\n",
    "    print (xi.shape)\n",
    "    print (xi)\n",
    "    return xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(966, 1850)\n",
      "[[-1.82780147 -1.78638351 -1.33596349 ..., -1.06674683 -0.97873384\n",
      "  -0.87001175]\n",
      " [ 2.10228515  2.23879075  1.87477553 ...,  1.85202491  2.65968299\n",
      "   2.36392117]\n",
      " [-0.2421792   0.09333889 -0.03128191 ..., -1.79514778 -1.71845794\n",
      "  -1.81432033]\n",
      " ..., \n",
      " [-1.27244699 -0.47461364 -0.1672515  ...,  0.09433326 -0.01684034\n",
      "  -0.09531575]\n",
      " [-1.86059082 -1.88377535 -1.75626004 ...,  0.53901821  0.6317569\n",
      "   0.70131075]\n",
      " [-1.01638567 -0.85002297 -0.8604207  ...,  1.6766088   1.78058577\n",
      "   1.8741647 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.82780147, -1.78638351, -1.33596349, ..., -1.06674683,\n",
       "        -0.97873384, -0.87001175],\n",
       "       [ 2.10228515,  2.23879075,  1.87477553, ...,  1.85202491,\n",
       "         2.65968299,  2.36392117],\n",
       "       [-0.2421792 ,  0.09333889, -0.03128191, ..., -1.79514778,\n",
       "        -1.71845794, -1.81432033],\n",
       "       ..., \n",
       "       [-1.27244699, -0.47461364, -0.1672515 , ...,  0.09433326,\n",
       "        -0.01684034, -0.09531575],\n",
       "       [-1.86059082, -1.88377535, -1.75626004, ...,  0.53901821,\n",
       "         0.6317569 ,  0.70131075],\n",
       "       [-1.01638567, -0.85002297, -0.8604207 , ...,  1.6766088 ,\n",
       "         1.78058577,  1.8741647 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale(xin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2028.775s\n",
      "Best estimator found by grid search:\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Best score found by grid search:\n",
      "0.542383771634\n",
      "Best params found by grid search:\n",
      "{'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "t0=time()\n",
    "n_neighbors= np.arange(1,201)\n",
    "parameters = {'n_neighbors': n_neighbors}\n",
    "mod= GridSearchCV(KNeighborsClassifier(),\n",
    "            parameters, cv=StratifiedKFold(n_splits=10),\n",
    "            n_jobs=-1, scoring= 'f1_weighted')\n",
    "mod = mod.fit(xin, yin)\n",
    "    \n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(mod.best_estimator_)\n",
    "print(\"Best score found by grid search:\")\n",
    "print(mod.best_score_)\n",
    "print(\"Best params found by grid search:\")\n",
    "print(mod.best_params_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
