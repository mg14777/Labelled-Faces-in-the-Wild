{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, LeaveOneOut\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "\n",
    "xin= np.load(\"./X_train.npy\")\n",
    "yin= np.load(\"./y_train.npy\")\n",
    "xout= np.load(\"./X_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dims=[50, 70, 75, 80, 90, 100, 120, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_components= 40\n",
    "\n",
    "pca = PCA(n_components=n_components, svd_solver='auto',\n",
    "              whiten=True).fit(xin)\n",
    "\n",
    "X_pca = pca.transform(xin)\n",
    "\n",
    "#print(pca.explained_variance_.shape)\n",
    "#print(pca.explained_variance_ratio_.shape)\n",
    "y=pca.explained_variance_\n",
    "#take the highest expl. variance\n",
    "#print(pca.explained_variance_)\n",
    "\n",
    "#print(pca.explained_variance_)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "#print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "x = np.arange(0, n_components) \n",
    "plt.xticks(x)\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dimReduction(n_components, X_train):\n",
    "\n",
    "    h= 50\n",
    "    w= 37\n",
    "    t0 = time()\n",
    "    print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "          % (n_components, X_train.shape[0]))\n",
    "    pca = PCA(n_components=n_components, svd_solver='auto',\n",
    "              whiten=True).fit(X_train)\n",
    "\n",
    "    eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "    print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "    X_pca = pca.transform(X_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.37088608  1.03670886  1.28481013  0.5         1.28227848  1.34810127\n",
      "  1.23164557]\n",
      "[ 0.82979727  0.87128713  0.84048405  0.93792236  0.84079837  0.83262612\n",
      "  0.84708471]\n"
     ]
    }
   ],
   "source": [
    "#unbalanced dataset!\n",
    "freq= itemfreq(yin)\n",
    "\n",
    "#print (freq)\n",
    "#print(freq[:,1])\n",
    "#print(np.sum(freq[:,1]))\n",
    "tot= np.sum(freq[:,1])\n",
    "sample_weight=(1-(np.sinh(freq[:,1]/(tot)))) \n",
    "sample_weight = sample_weight / float(max(sample_weight))\n",
    "#print(sample_weight)\n",
    "\n",
    "w2= 1.5 - freq[:,1]/max(freq[:,1])\n",
    "print (w2)\n",
    "w3= 1 - w2/np.sum(w2)\n",
    "print(w3)\n",
    "\n",
    "dic1= {0: sample_weight[0],\n",
    "      1: sample_weight[1],\n",
    "      2: sample_weight[2],\n",
    "      3: sample_weight[3],\n",
    "      4: sample_weight[4],\n",
    "      5: sample_weight[5],\n",
    "      6: sample_weight[6],\n",
    "     }\n",
    "\n",
    "dic2= {0: w2[0],\n",
    "      1: w2[1],\n",
    "      2: w2[2],\n",
    "      3: w2[3],\n",
    "      4: w2[4],\n",
    "      5: w2[5],\n",
    "      6: w2[6],\n",
    "     }\n",
    "\n",
    "dic3= {0: w3[0],\n",
    "      1: w3[1],\n",
    "      2: w3[2],\n",
    "      3: w3[3],\n",
    "      4: w3[4],\n",
    "      5: w3[5],\n",
    "      6: w3[6],\n",
    "     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export(filename, x):\n",
    "    fo = open( filename , 'w' )\n",
    "    fo.write(x)\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniformDataset(x, y):\n",
    "    freq= itemfreq(y)\n",
    "    minOcc= min(freq[:,1])\n",
    "    #print(minOcc)\n",
    "    xred= np.empty((0,1850))\n",
    "    yred= np.array([])\n",
    "    for i in range(y.shape[0]):\n",
    "        freqnew= itemfreq(yred)\n",
    "        if(freqnew.shape== (7,2)):\n",
    "            occ= freqnew[y[i],1]\n",
    "        else:\n",
    "            occ= 0\n",
    "        if(occ <= minOcc):\n",
    "            xred= np.vstack((xred, [x[i, :]]))\n",
    "            yred= np.append(yred, y[i])\n",
    "    return (xred,yred)\n",
    "    #print(xred.shape)\n",
    "    #print(yred.shape)\n",
    "    #print(itemfreq(yred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weightedF1(y, predictions):\n",
    "    f1= f1_score(y, predictions, average=None)\n",
    "    occ= itemfreq(y)\n",
    "    count= np.sum(occ[:,1])\n",
    "    score= 0.0\n",
    "    v=np.empty(occ[:,1].shape[0])\n",
    "    for i in range(len(f1)):\n",
    "        v[i]= (1-occ[i,1]/count)*f1[i]\n",
    "        score = score+ (1-occ[i,1]/count)*f1[i]\n",
    "    return score\n",
    "#y=[1, 2, 3, 3, 3]\n",
    "#pred=[1, 2, 2, 3, 1]\n",
    "#r=weightedF1(y, pred)\n",
    "#print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildModel(param_grid, dim, x, y):\n",
    "    t0 = time()\n",
    "    x_n= dimReduction(dim, x)\n",
    "    print(\"Fitting the classifier to the training set\")\n",
    "    #f1custom= make_scorer(weightedF1, greater_is_better=True)\n",
    "    model = GridSearchCV(SVC(decision_function_shape='ovr'),\n",
    "            param_grid, cv=StratifiedKFold(n_splits=10),\n",
    "            n_jobs=-1, scoring='f1_weighted')\n",
    "    model = model.fit(x_n, y)\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"DIMENSIONS:\")\n",
    "    print(dim)\n",
    "    #print(\"ker:\")\n",
    "    #print(ker)\n",
    "    #print(\"Best estimator found by grid search:\")\n",
    "    #print(model.best_estimator_)\n",
    "    print(\"Best score found by grid search:\")\n",
    "    print(model.best_score_)\n",
    "    print(\"Best params found by grid search:\")\n",
    "    print(model.best_params_)\n",
    "    print(\"\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, x, y):\n",
    "    t0 = time()\n",
    "    print(\"Predicting people's names on the test set\")\n",
    "    y_pred = model.predict(x)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    score= f1_score(y, y_pred, average='weighted')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 80 eigenfaces from 966 faces\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.236s\n",
      "Fitting the classifier to the training set\n",
      "done in 368.013s\n",
      "DIMENSIONS:\n",
      "80\n",
      "Best score found by grid search:\n",
      "0.84836648069\n",
      "Best params found by grid search:\n",
      "{'kernel': 'rbf', 'gamma': 0.0078125, 'C': 8.0, 'class_weight': {0: 0.82979726544082977, 1: 0.87128712871287128, 2: 0.84048404840484048, 3: 0.93792236366493786, 4: 0.84079836555084075, 5: 0.83262611975483258, 6: 0.84708470847084705}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best: \n",
      "0.84836648069\n",
      "params:\n",
      "{'kernel': 'rbf', 'gamma': 0.0078125, 'C': 8.0, 'class_weight': {0: 0.82979726544082977, 1: 0.87128712871287128, 2: 0.84048404840484048, 3: 0.93792236366493786, 4: 0.84079836555084075, 5: 0.83262611975483258, 6: 0.84708470847084705}}\n",
      "dim\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "a=2\n",
    "expC= np.arange(-5.,17.)\n",
    "c=np.power(a, expC)\n",
    "\n",
    "expG= np.arange(-15.,4.)\n",
    "\n",
    "gam=np.power(a, expG)\n",
    "\n",
    "\n",
    "param_grid = {'C': c,\n",
    "              'gamma': gam,\n",
    "              'kernel':['rbf'],\n",
    "              'class_weight': [dic3]\n",
    "             }\n",
    "\n",
    "dims=[80]\n",
    "\n",
    "#(xnew,ynew)=uniformDataset(xin,yin)\n",
    "\n",
    "result=0.0\n",
    "\n",
    "for i in range(len(dims)):\n",
    "    model= buildModel(param_grid, dims[i], xin, yin)\n",
    "    tmp= model.best_score_\n",
    "    if(tmp > result):\n",
    "        result=  tmp\n",
    "        params= model.best_params_\n",
    "        d= dims[i]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Best: \")\n",
    "print(result)\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print(\"dim\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "a=2\n",
    "expC= np.arange(-5.,17.)\n",
    "c= [2]\n",
    "\n",
    "#expG= np.arange(-15.,4.)\n",
    "#gam=np.power(a, expG)\n",
    "\n",
    "gam= [0.0078125,0.008 ,0.006, 0.005, 0.002, 0.001 , 0.009, 0.008,\n",
    "      0.0095, 0.0099, 0.01, 0.03, 0.04, 0.05, 0.0085, 0.0001 \n",
    "      , 0.0009, 0.0005, 0.0007, 0.0001, 0.02, 0.1, 0.5, 0.75,\n",
    "     0.9, 1, 0.00001, 0.00003, 0.0008]\n",
    "\n",
    "param_grid = {'C': c,\n",
    "              'gamma': gam,\n",
    "              'kernel':['rbf'],\n",
    "              'class_weight': [dic2]\n",
    "             }\n",
    "\n",
    "dims=[80]\n",
    "\n",
    "#(xnew,ynew)=uniformDataset(xin,yin)\n",
    "\n",
    "result=0.0\n",
    "\n",
    "for i in range(len(dims)):\n",
    "    model= buildModel(param_grid, dims[i], xin, yin)\n",
    "    tmp= model.best_score_\n",
    "    if(tmp > result):\n",
    "        result=  tmp\n",
    "        params= model.best_params_\n",
    "        d= dims[i]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Best: \")\n",
    "print(result)\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print(\"dim\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CHI square test\n",
    "def chisq(xin, yin, k):\n",
    "    \n",
    "    x_new = SelectKBest(f_classif, k=k).fit_transform(xin,yin)\n",
    "    \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modChi(ker, param_grid, k, x, y):\n",
    "    t0 = time()\n",
    "    xin= chisq(x,y,k)\n",
    "    print(\"Fitting the classifier to the training set\")\n",
    "    model = GridSearchCV(SVC(kernel=ker, class_weight='balanced', decision_function_shape='ovr'), param_grid, cv=5, scoring='f1_micro')\n",
    "    model = model.fit(xin, y)\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"DIMENSIONS:\")\n",
    "    print(k)\n",
    "    print(\"ker:\")\n",
    "    print(ker)\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(model.best_estimator_)\n",
    "    print(\"Best score found by grid search:\")\n",
    "    print(model.best_score_)\n",
    "    print(\"Best params found by grid search:\")\n",
    "    print(model.best_params_)\n",
    "    print(\"\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [1],\n",
    "              'gamma': [0.008, 0.009, 0.0085, 0.01], }\n",
    "\n",
    "k= [100]\n",
    "\n",
    "result=0.0\n",
    "\n",
    "for i in range(len(k)):\n",
    "    model= modChi('rbf',param_grid, k[i], xin, yin)\n",
    "    tmp= model.best_score_\n",
    "    if(tmp > result):\n",
    "        result=  tmp\n",
    "        params= model.best_params_\n",
    "        dim= k[i]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Best: \")\n",
    "print(result)\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print(\"dim\")\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [100, 50, 20, 10, 1, 0.1, 0.001, 0.0001],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.005, 0.0001, 0.0005, 0.000001], \n",
    "              'coef0': [0, 0.01, 0.001, 0.0001, 100, 1000]}\n",
    "\n",
    "result= 0.0\n",
    "\n",
    "for i in range(len(dims)):\n",
    "    model= buildModel('sigmoid',param_grid, dims[i], xin, yin)\n",
    "    tmp= model.best_score_\n",
    "    if(tmp > result):\n",
    "        result=  tmp\n",
    "        params= model.best_params_\n",
    "        d= dims[i]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Best: \")\n",
    "print(result)\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print(\"dim\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "param_range = np.logspace(-5, -1, 5)\n",
    "x_in= dimReduction(90,xin)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    SVC(C=1), x_in, yin, param_name=\"gamma\", param_range=param_range,\n",
    "    cv=2, scoring=\"f1_micro\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "param_range = np.logspace(-2.3, -1, 5)\n",
    "print(param_range)\n",
    "x_in= dimReduction(75,xin)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    SVC(C=1), x_in, yin, param_name=\"gamma\", param_range=param_range,\n",
    "    cv=StratifiedKFold(n_splits=3), scoring=\"f1_micro\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
