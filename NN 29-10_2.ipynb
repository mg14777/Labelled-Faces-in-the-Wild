{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import zscore\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import itemfreq\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createSubmission(filename, y):\n",
    "    fo = open( filename , 'w' )\n",
    "    fo.write(\"ImageId,PredictedClass\\n\")\n",
    "    for i in range(y.shape[0]):\n",
    "        fo.write(str(i)+\",\"+str(y[i])+\"\\n\")\n",
    "    fo.close()\n",
    "\n",
    "def nnPredict(model,x, y):\n",
    "    ypredict= model.predict(x)\n",
    "    score= f1_score(y , ypredict, average='macro');\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xin= np.load(\"./X_train.npy\")\n",
    "yin= np.load(\"./y_train.npy\")\n",
    "xout= np.load(\"./X_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scale data\n",
    "def normalize(x):\n",
    "    r=zscore(x, axis=0)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overSampling(x, y):\n",
    "    sm = SMOTE(kind='svm')\n",
    "    x_resampled, y_resampled = sm.fit_sample(x, y)\n",
    "    return (x_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(996, 1850)\n",
      "(966, 1850)\n",
      "[[  0  51]\n",
      " [  1 183]\n",
      " [  2  85]\n",
      " [  3 395]\n",
      " [  4  86]\n",
      " [  5  60]\n",
      " [  6 106]]\n",
      "[[  0 205]\n",
      " [  1 136]\n",
      " [  2  57]\n",
      " [  3 277]\n",
      " [  4  62]\n",
      " [  5 193]\n",
      " [  6  66]]\n"
     ]
    }
   ],
   "source": [
    "xin= np.load(\"./X_train.npy\")\n",
    "yin= np.load(\"./y_train.npy\")\n",
    "x= xin\n",
    "y= yin\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=0)\n",
    "for _ in range(2):\n",
    "    x_train,y_train = overSampling(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(x.shape)\n",
    "print(itemfreq(yin))\n",
    "print(itemfreq(y_train))\n",
    "\n",
    "x_train= normalize(x_train)\n",
    "x_test= normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance in sample:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       205\n",
      "          1       1.00      1.00      1.00       136\n",
      "          2       1.00      1.00      1.00        57\n",
      "          3       1.00      1.00      1.00       277\n",
      "          4       1.00      1.00      1.00        62\n",
      "          5       1.00      1.00      1.00       193\n",
      "          6       1.00      1.00      1.00        66\n",
      "\n",
      "avg / total       1.00      1.00      1.00       996\n",
      "\n",
      "\n",
      "[ 1.  1.  1.  1.  1.  1.  1.]\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.76      0.67        17\n",
      "          1       0.71      0.74      0.73        47\n",
      "          2       0.85      0.79      0.81        28\n",
      "          3       0.94      0.86      0.89       118\n",
      "          4       0.80      0.67      0.73        24\n",
      "          5       0.47      0.88      0.61        16\n",
      "          6       0.94      0.82      0.88        40\n",
      "\n",
      "avg / total       0.83      0.81      0.81       290\n",
      "\n",
      "\n",
      "[ 0.66666667  0.72916667  0.81481481  0.89380531  0.72727273  0.60869565\n",
      "  0.88      ]\n",
      "\n",
      "F1 _macro:0.760060262476\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(1851,400,),\n",
    "                   activation= 'tanh',\n",
    "                   solver= 'lbfgs',\n",
    "                   alpha= 4,\n",
    "                   max_iter= 500,\n",
    "                   learning_rate_init= 0.001,\n",
    "                   verbose= True,\n",
    "                   early_stopping= True,\n",
    "                   validation_fraction= 0.3,\n",
    "                   tol= 0.0001\n",
    "                  )\n",
    "\n",
    "nn.fit(x_train,y_train)\n",
    "y_p= nn.predict(x_train)\n",
    "print('Performance in sample:\\n')\n",
    "print(classification_report(y_train, y_p))\n",
    "print()\n",
    "print(f1_score(y_train, y_p, average= None))\n",
    "print()\n",
    "y_pred = nn.predict(x_test)\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(f1_score(y_test, y_pred, average= None))\n",
    "print()\n",
    "score= nnPredict(nn, x_test, y_test)\n",
    "print(\"F1 _macro:\" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_in= xin\n",
    "y_in= yin\n",
    "for _ in range(2):\n",
    "    x_in,y_in = overSampling(x_in, y_in)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NEURAL_NETWORK_ARCH = ((1851,400,))\n",
    "DATE = '10_29_2'\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(1851,400,),\n",
    "                   activation= 'tanh',\n",
    "                   solver= 'lbfgs',\n",
    "                   alpha= 4,\n",
    "                   max_iter= 500,\n",
    "                   learning_rate_init= 0.001,\n",
    "                   verbose= True,\n",
    "                   early_stopping= True,\n",
    "                   validation_fraction= 0.3,\n",
    "                   tol= 0.0001\n",
    "                  )\n",
    "x_in= normalize(x_in)\n",
    "nn.fit(x_in,y_in)\n",
    "\n",
    "# Run the trained neural network on the test set and write results to a csv file\n",
    "filename = './submission_nn_' + DATE + '_' + str(NEURAL_NETWORK_ARCH) + '.csv'\n",
    "x_out= normalize(xout)\n",
    "y_out = nn.predict(x_out)\n",
    "createSubmission(filename, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Score on Kaggle achived: 0.83230 "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
